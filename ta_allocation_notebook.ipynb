{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "import numpy as np\n",
    "# import re\n",
    "# from fuzzywuzzy import process, fuzz\n",
    "\n",
    "# Display all rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd = \"DSD2324_overview (2).xlsx\"\n",
    "preferences = \"Teaching Preferences Questionnaire_S1_2023-24_raw.xlsx\"\n",
    "contract = \"ta_contract.xlsx\"\n",
    "bs_weights = \"bs_courses_weights_FILLED.xlsx\"\n",
    "term = \"S1\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMAND - practical lessons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd_df = pd.read_excel(dsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd_df[\"course\"] = dsd_df[\"COURSE CODE\"].astype(str) + \" || \" + dsd_df[\"COURSE NAME\"].astype(str) + \" || \" + dsd_df[\"TERM\"].astype(str) + \" || \" + dsd_df[\"LANGUAGE\"].astype(str)\n",
    "\n",
    "# ADDED!\n",
    "faculty_list = dsd_df[dsd_df[\"COURSE NAME\"] != \"Stata\"][\"FACULTY EMAIL\"].unique()\n",
    "\n",
    "if term == \"S1\":\n",
    "    selected_terms = [\"S1\", \"T1\", \"T2\"]\n",
    "    dsd_df = dsd_df[dsd_df['TERM'].isin(selected_terms)]\n",
    "else:\n",
    "    selected_terms = [\"S2\", \"T3\", \"T4\"]\n",
    "    dsd_df = dsd_df[dsd_df['TERM'].isin(selected_terms)]\n",
    "\n",
    "# ADDED!\n",
    "teorico_practicas = dsd_df[(dsd_df[\"FACULTY NAME\"].isna()) & (dsd_df[\"CYCLE\"] == \"BSC\")][\"COURSE NAME\"].unique()\n",
    "dsd_df = dsd_df.drop(dsd_df[(dsd_df[\"COURSE NAME\"].isin(teorico_practicas)) & (dsd_df[\"FACULTY NAME\"].notna())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_functions = {\n",
    "    'CLASS': 'count',\n",
    "    'SLOTS': np.sum\n",
    "    # 'COURSE NAME': 'first'  # Add 'COURSE NAME' to the aggregation functions\n",
    "}\n",
    "\n",
    "# ADDED! \"CYCLE\"\n",
    "output_1 = dsd_df.groupby(['COURSE NAME', 'TERM', 'COURSE CODE', 'LANGUAGE', 'CYCLE']).agg(agg_functions).reset_index()\n",
    "output_1 = output_1.rename(columns={'CLASS': 'Nº CLASSES', 'SLOTS': 'Nº STUDENTS'})\n",
    "\n",
    "\n",
    "output_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsd_df.TERM.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED!\n",
    "course_demand = dsd_df[dsd_df['CYCLE'].isin(['MST', 'BSC'])]\n",
    "\n",
    "course_demand = course_demand.groupby(['course']).agg(agg_functions).reset_index()\n",
    "course_demand = course_demand.rename(columns={'CLASS': 'number_classes', 'SLOTS': 'number_students'})\n",
    "\n",
    "# ADDED!\n",
    "full_courses = dsd_df[dsd_df['CYCLE'].isin(['MST', 'BSC', 'ME'])]\n",
    "full_courses = full_courses.groupby(['course', 'CYCLE', 'TERM']).agg(agg_functions).reset_index()\n",
    "\n",
    "course_demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_courses.CYCLE.value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPLY - TA hours (current contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = pd.read_excel(contract)\n",
    "\n",
    "contract = contract[[\"TA\", \"CONTRACT\"]]\n",
    "contract[\"TA\"] = contract[\"TA\"].str.lower()\n",
    "\n",
    "# Zero contracts\n",
    "# ADDED! Caps \"CONTRACT\", remove faculty\n",
    "zero_contracts = contract[contract['CONTRACT'] == 0][\"TA\"].unique()\n",
    "contract = contract[contract['CONTRACT'] != 0]\n",
    "contract = contract[~contract['TA'].isin(faculty_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "contract[contract.duplicated()].TA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_emails = contract.TA.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPLY - TA preferences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file with the second row as the header\n",
    "preferences_df = pd.read_excel(preferences, header=1)\n",
    "\n",
    "# Sort the DataFrame by \"End Date\" column in descending order\n",
    "preferences_df = preferences_df.sort_values(by='End Date', ascending=False)\n",
    "\n",
    "# Rename the column to \"TA\"\n",
    "preferences_df.rename(columns={'Please write your E-mail @novasbe.pt': 'TA'}, inplace=True)\n",
    "\n",
    "# Convert the values in the \"TA\" column to lowercase\n",
    "preferences_df['TA'] = preferences_df['TA'].str.lower()\n",
    "\n",
    "# Create a new dataframe with column names and zero-indexed column numbers\n",
    "column_df = pd.DataFrame({'Column Name': preferences_df.columns,\n",
    "                          'Column Number': range(len(preferences_df.columns))})\n",
    "\n",
    "# Remove TAs with zero_contracts\n",
    "preferences_df = preferences_df[~preferences_df[\"TA\"].isin(zero_contracts)]\n",
    "\n",
    "# ADDED! Remove TAs wicha are faculty\n",
    "preferences_df = preferences_df[~preferences_df[\"TA\"].isin(faculty_list)]\n",
    "\n",
    "# Create a mask to identify duplicates in the \"TA\" column\n",
    "duplicates_mask = preferences_df.duplicated(subset='TA', keep=False)\n",
    "preferences_duplicates = preferences_df[duplicates_mask]\n",
    "preferences_duplicates = preferences_duplicates.sort_values(by='End Date', ascending=False)\n",
    "\n",
    "preferences_duplicates_last = preferences_duplicates.drop_duplicates(subset='TA', keep='first').copy()\n",
    "\n",
    "# Create a mask to check if columns 31:81 or 83:347 have values\n",
    "value_mask = preferences_duplicates.iloc[:, 31:81].notnull().any(axis=1) | preferences_duplicates.iloc[:, 83:347].notnull().any(axis=1)\n",
    "preferences_duplicates_values = preferences_duplicates[value_mask]\n",
    "preferences_duplicates_values = preferences_duplicates_values.drop_duplicates(subset='TA', keep='first').copy()\n",
    "\n",
    "# Drop duplicates based on the \"TA\" column\n",
    "preferences_df = preferences_df[~duplicates_mask]\n",
    "\n",
    "# Drop duplicates based on the \"Full Name\" column while keeping the row with the most recent \"End Date\" (ex. Franziska wrong)\n",
    "preferences_df = preferences_df.drop_duplicates(subset='Full Name', keep='first')\n",
    "\n",
    "# Create a new DataFrame with columns from preferences_duplicates_last\n",
    "preferences_df_final = preferences_duplicates_last.copy()\n",
    "\n",
    "# Get the relevant columns from preferences_duplicates_values\n",
    "preference_columns = preferences_duplicates_values.columns[31:81].tolist() + preferences_duplicates_values.columns[83:347].tolist()\n",
    "\n",
    "# Update the values in preferences_df_final using values from preferences_duplicates_values for preference_columns\n",
    "preferences_df_final.set_index('TA', inplace=True, drop=False)\n",
    "preferences_duplicates_values.set_index('TA', inplace=True, drop=False)\n",
    "preferences_df_final.loc[preferences_duplicates_values.index, preference_columns] = preferences_duplicates_values[preference_columns].values\n",
    "\n",
    "# Concatenate the remaining columns from preferences_df to preferences_df_final\n",
    "preferences_df_final = pd.concat([preferences_df_final, preferences_df])\n",
    "\n",
    "# Sort the final DataFrame by \"End Date\" column in descending order\n",
    "preferences_df_final.sort_values(by='End Date', ascending=False, inplace=True)\n",
    "\n",
    "# Reset the index of the final DataFrame\n",
    "preferences_df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop duplicates based on the \"Full Name\" column while keeping the row with the most recent \"End Date\" (ex. Franziska wrong )\n",
    "preferences_df_final.drop_duplicates(subset='Full Name', keep='first', inplace=True)\n",
    "\n",
    "# Create a mapping of original column names to new column names (course ID as integer)\n",
    "mapping = {}\n",
    "# course_full_codes = []\n",
    "\n",
    "for column_name in preference_columns:\n",
    "    # Extract the course ID number from the column name\n",
    "    # course_id = column_name.split(' || ')[0].split(' - ')[3] + \" || \" + column_name.split(' || ')[1] + ' || ' +  column_name.split(' || ')[2].split(' - ')[0]\n",
    "    course_id = column_name.split(' || ')[0].split(' - ')[3] + \" || \"  + column_name.split(' || ')[0].split(' - ')[4]+ \" || \" + column_name.split(' || ')[1] + ' || ' +  column_name.split(' || ')[2].split(' - ')[0]\n",
    "    \n",
    "    # Extract full course ID for matching later\n",
    "    # course_full_codes.append(column_name.split(' || ')[0].split(' - ')[3] + \" || \"  + column_name.split(' || ')[0].split(' - ')[4]+ \" || \" + column_name.split(' || ')[1] + ' || ' +  column_name.split(' || ')[2].split(' - ')[0])\n",
    "    \n",
    "    # Map the original column name to the course ID\n",
    "    mapping[column_name] = course_id\n",
    "\n",
    "# Remove duplicates\n",
    "# course_full_codes = list(set(course_full_codes))\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "preferences_df_final.rename(columns=mapping, inplace=True)\n",
    "\n",
    "# Drop columns with list of courses (redundant) [30, 81, and 82]\n",
    "preferences_df_final.drop(columns=preferences_df_final.iloc[:,[30, 81, 82]], inplace=True)\n",
    "\n",
    "# OUTPUT #2\n",
    "# Filter the DataFrame for rows where \"Do you intend to continue your collaboration with Nova SBE next semester as Teaching Assistant?\" \n",
    "# (column 20) is not equal to \"No\"\n",
    "ta_exits = preferences_df_final[preferences_df_final.iloc[:, 19] == \"No\"].iloc[:, [17, 18, 20]]\n",
    "ta_exits = ta_exits.rename(columns={ta_exits.columns[-1]: \"Comments\"}).sort_values(\"Full Name\")\n",
    "\n",
    "# ta_exits.to_excel(\"ta_exits_v1.xlsx\", index=False)\n",
    "ta_exits_list = ta_exits.TA.unique()\n",
    "\n",
    "preferences_df_final = preferences_df_final[preferences_df_final.iloc[:, 19] != \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_17 = column_df[column_df['Column Name'] == \"Full Name\"].iloc[0][\"Column Number\"]\n",
    "column_18 = column_df[column_df['Column Name'] == \"TA\"].iloc[0][\"Column Number\"]\n",
    "\n",
    "continue_str = \"Do you intend to continue your collaboration with Nova SBE next semester\"\n",
    "continue_just_str = \"Please write here a short justification on why you do not intend to continue\"\n",
    "bs_or_ms_str = \"Do you prefer to be assigned to Bachelor’s or Master's courses?\"\n",
    "load_availability_str = \"What is your availability in terms of workload and contract percentage for the next semester?\"\n",
    "ms_student_str = \"In the upcoming semester, are you going to be a Nova SBE student?\"\n",
    "phd_restrictions_str = \"Being a PhD student, do you have any constraint in the number of teaching hours or contract percentage\"\n",
    "new_workload_str = \"What is your availability in terms of workload and contract percentage for the next semester\"\n",
    "\n",
    "column_19 = column_df[column_df['Column Name'].str.startswith(continue_str)].iloc[0][\"Column Number\"]\n",
    "column_20 = column_df[column_df['Column Name'].str.startswith(continue_just_str)].iloc[0][\"Column Number\"]\n",
    "column_21 = column_df[column_df['Column Name'].str.startswith(ms_student_str)].iloc[0][\"Column Number\"]\n",
    "column_22 = column_df[column_df['Column Name'].str.startswith(bs_or_ms_str)].iloc[0][\"Column Number\"]\n",
    "column_23 = column_df[column_df['Column Name'].str.startswith(phd_restrictions_str)].iloc[0][\"Column Number\"]\n",
    "column_27 = column_df[column_df['Column Name'].str.startswith(load_availability_str)].iloc[0][\"Column Number\"]\n",
    "column_28 = column_27 + 1\n",
    "column_29 = column_28 + 1 # Be careful! This assumes there are TWO text boxes for available workload percentage\n",
    "\n",
    "bs_str = \"Please choose below your teaching preferences for Bachelor Courses.\"\n",
    "column_30 = column_df[column_df['Column Name'].str.startswith(bs_str)].iloc[0][\"Column Number\"]\n",
    "column_31 = column_30 + 1 # BE careful! This assumes there is ONE open text columns for bachelors preferences\n",
    "\n",
    "ms_str = \"Please choose below your teaching preferences for Masters Courses (grading).\"\n",
    "column_81 = column_df[column_df['Column Name'].str.startswith(ms_str)].iloc[0][\"Column Number\"]\n",
    "column_82 = column_81 + 1 # BE careful! This assumes there are TWO open text columns for master preferences\n",
    "column_83 = column_81 + 2 # BE careful! This assumes there are TWO open text columns for master preferences\n",
    "\n",
    "print(column_17, column_18, column_19, column_20, column_21, column_22, column_23, column_27, column_28, column_29, column_30, column_31, column_81, column_82, column_83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_df.iloc[column_28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of TAs who are leaving: {len(ta_exits_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that can use the email as key/ ID\n",
    "preferences_df_final[\"TA\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no duplicates names\n",
    "preferences_df_final[preferences_df_final[\"Full Name\"].duplicated()][\"Response ID\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no duplicates answers\n",
    "preferences_df_final[preferences_df_final[\"TA\"].duplicated()][\"Response ID\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responded_number = preferences_df_final.shape[0] \n",
    "print(f\"Number of TAs willing to continue who responded: {responded_number}\")\n",
    "display(preferences_df_final[[\"TA\", \"Full Name\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT #N\n",
    "preferences_df_final[~preferences_df_final.iloc[:,-1].isna()].iloc[:, [17, 18, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT #N\n",
    "preferences_df_final[~preferences_df_final[\"TA\"].isin(contract_emails)][[\"TA\", \"Full Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the course columns\n",
    "course_columns = preferences_df_final.columns[30:-1]\n",
    "\n",
    "# Create a new DataFrame for the adapted format\n",
    "adapted_df = pd.DataFrame(columns=[\"TA\", \"course\", \"preference\", \"preference_type\"])\n",
    "\n",
    "# Define the translation mapping for column 22 values\n",
    "translation_mapping = {\n",
    "    \"Masters' Courses\": 2,\n",
    "    \"Bachelors' Courses\": 0,\n",
    "    \"Indifferent\": 1,\n",
    "    pd.NaT: 1  # Assuming NaN values should also be considered \"Indifferent\"\n",
    "}\n",
    "\n",
    "# Iterate over the course columns\n",
    "for course in course_columns:\n",
    "    # Check if the course has already been processed\n",
    "    if course in adapted_df[\"course\"].unique():\n",
    "        continue\n",
    "\n",
    "    # Get the duplicate columns for the current course\n",
    "    duplicate_columns = [col for col in course_columns if col != course and col.endswith(course)]\n",
    "\n",
    "    # Combine the duplicate columns into a single column\n",
    "    combined_column = preferences_df_final[[course] + duplicate_columns].ffill(axis=1).iloc[:, -1]\n",
    "\n",
    "    # Filter the DataFrame for non-null values in the combined column\n",
    "    non_null_mask = combined_column.notnull()\n",
    "    non_null_df = preferences_df_final[non_null_mask]\n",
    "\n",
    "    # Get the teacher names and their corresponding preference rankings for the current course\n",
    "    teacher_names = non_null_df[\"TA\"]\n",
    "    preference_rankings = combined_column[non_null_mask]\n",
    "\n",
    "    # Get the corresponding preference types based on the translation mapping\n",
    "    preference_types = non_null_df.iloc[:, 22].map(translation_mapping)\n",
    "\n",
    "    # Create a DataFrame for the current course, preference rankings, and preference types\n",
    "    course_df = pd.DataFrame({\"TA\": teacher_names, \"course\": [course] * len(teacher_names),\n",
    "                              \"preference\": preference_rankings, \"preference_type\": preference_types})\n",
    "\n",
    "    # Concatenate course_df with adapted_df\n",
    "    adapted_df = pd.concat([adapted_df, course_df], ignore_index=True)\n",
    "    \n",
    "    # Create the 'masters_course' column based on the condition\n",
    "    adapted_df['masters_course'] = adapted_df['course'].apply(lambda x: 0 if x.split(' ')[0].startswith('1') else 1)\n",
    "\n",
    "    # Convert \"preference\" column to integers\n",
    "    adapted_df['preference'] = adapted_df['preference'].astype(np.int8)\n",
    "\n",
    "    # Remove preferences above 5\n",
    "    adapted_df = adapted_df[adapted_df['preference']<=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no preferences above 5 and below 1\n",
    "print(adapted_df['preference'].min())\n",
    "print(adapted_df['preference'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_preferences = adapted_df[\"TA\"].unique()\n",
    "completed_preferences_number = len(completed_preferences)\n",
    "print(f\"Number of TAs with completed preferences: {completed_preferences_number}\")\n",
    "# display(completed_preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT #6\n",
    "# ADDED! removed :-1\n",
    "# adapted_df.iloc[:,:-1].head()\n",
    "adapted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_df[adapted_df[\"TA\"]==\"bernardo.costa@novasbe.pt\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. New contract (preferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_list = contract[(~contract.TA.isin(completed_preferences)) & (~contract.TA.isin(ta_exits_list))]\n",
    "print(contact_list.shape[0])\n",
    "display(contact_list)\n",
    "contact_list.to_excel(\"ta_contact_list_v1.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_closest(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    else:\n",
    "        # rounded_value = round(value * 8) / 8  # Round to the nearest multiple of 0.125\n",
    "        capped_value = min(value, 0.5)  # Cap the value at 0.5\n",
    "        capped_value = max(value, 0.1)  # Cap the value at 0.1\n",
    "        return capped_value\n",
    "\n",
    "# Clean the \"load_requested\" column\n",
    "def clean_percentage(value):\n",
    "    if pd.isnull(value):\n",
    "        return value\n",
    "    elif isinstance(value, str):\n",
    "        # Check if the value contains only text characters\n",
    "        if value.isalpha():\n",
    "            return np.nan\n",
    "\n",
    "        # Extract numeric values from string\n",
    "        numeric_value = ''.join(filter(str.isdigit, value))\n",
    "\n",
    "        if numeric_value == '':\n",
    "            return np.nan\n",
    "\n",
    "        if numeric_value == '100':\n",
    "            return 100\n",
    "\n",
    "        if len(numeric_value) >= 2:\n",
    "            integer_part = numeric_value[:2]\n",
    "            decimal_part = numeric_value[2:]\n",
    "            return float(integer_part + '.' + decimal_part)\n",
    "\n",
    "        return np.nan\n",
    "\n",
    "    elif isinstance(value, (int, float)):\n",
    "        return float(value) / 100\n",
    "\n",
    "    return value\n",
    "\n",
    "def decrease_contract_level(value):\n",
    "    return value - 0.125\n",
    "\n",
    "\n",
    "mapping = {\n",
    "    \"I want to increase the contract percentage/workload in the next semester (please specify the desired contract percentage level)\": 1,\n",
    "    \"I want to keep the same contract percentage/workload as this semester\": 0,\n",
    "    \"I want to reduce the contract percentage/workload in the next semester (please specify the desired contract percentage level)\": -1,\n",
    "    pd.NaT: 0\n",
    "}\n",
    "\n",
    "mapping_21 = {\n",
    "    \"Yes, I am a PhD student\": 0,\n",
    "    \"Yes, I will be a Masters student but not doing any courses, only the Work Project\": 0,\n",
    "    \"Yes, I will be a Masters student and I will be doing at least one more course\": 1,\n",
    "    \"No\": 0,\n",
    "    pd.NaT: 0\n",
    "}\n",
    "\n",
    "mapping_23 = {\n",
    "    \"Yes, I have some other constraints that limit my teaching hours/workload (please specify the reason and the limit)\": 1,\n",
    "    \"Yes, I have a FCT scholarship that limits my weekly teaching hours to 4h per week\": 1,\n",
    "    \"No\": 0,\n",
    "    pd.NaT: 0\n",
    "}\n",
    "\n",
    "################################################################################################################################################\n",
    "\n",
    "mask = preferences_df_final.iloc[:, 27].notna()\n",
    "new_contract = preferences_df_final[mask].iloc[:, [18, 21, 23, 27, 28, 29]]\n",
    "\n",
    "new_contract.columns = ['TA', 'master_student', 'PhD_restrictions', 'change_load', 'new_contract_decreased_load', 'new_contract_increased_load']\n",
    "new_contract['change_load'] = new_contract['change_load'].map(mapping)\n",
    "new_contract['master_student'] = new_contract['master_student'].map(mapping_21).fillna(0).astype(int)\n",
    "new_contract['PhD_restrictions'] = new_contract['PhD_restrictions'].map(mapping_23).fillna(0).astype(int)\n",
    "\n",
    "# Convert TA column to lowercase\n",
    "new_contract['TA'] = new_contract['TA'].str.lower()\n",
    "\n",
    "new_contract['new_contract_decreased_load'] = new_contract['new_contract_decreased_load'].apply(clean_percentage) / 100\n",
    "new_contract['new_contract_increased_load'] = new_contract['new_contract_increased_load'].apply(clean_percentage) / 100\n",
    "\n",
    "# Merge \"new_contract_decreased_load\" and \"new_contract_increased_load\" into \"load_requested\"\n",
    "new_contract['load_requested'] = new_contract[['new_contract_decreased_load', 'new_contract_increased_load']].mean(axis=1)\n",
    "new_contract['load_requested'] = new_contract['load_requested'].apply(round_to_closest)\n",
    "\n",
    "# Drop \"new_contract_decreased_load\" and \"new_contract_increased_load\" columns\n",
    "new_contract.drop(columns=['new_contract_decreased_load', 'new_contract_increased_load'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT #3\n",
    "new_contract[new_contract.change_load !=0].sort_values(by=\"change_load\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new_contract_load is formatted correctly\n",
    "# new_contract.load_requested.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_TAS = len(new_contract[new_contract.change_load.isin([1,-1])])\n",
    "print(f\"Number of TAs who want to change their contract: {number_TAS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contracts = contract.merge(new_contract, how=\"left\", on=\"TA\")\n",
    "\n",
    "# Filter rows where change_load is not equal to 0\n",
    "filtered_contracts = all_contracts[all_contracts['change_load'] != 0].copy()\n",
    "\n",
    "# Decrease contract to load_requested for rows where change_load is -1\n",
    "filtered_contracts.loc[filtered_contracts['change_load'] == -1, 'new_contract'] = filtered_contracts['load_requested']\n",
    "# ADDED! Caps \"CONTRACT\"\n",
    "filtered_contracts.loc[(filtered_contracts['change_load'] == -1) & (filtered_contracts['load_requested'].isnull()), 'new_contract'] = filtered_contracts.apply(lambda row: decrease_contract_level(row['CONTRACT']), axis=1)\n",
    "\n",
    "# # Increase contract for no restrictions\n",
    "# filtered_contracts.loc[(filtered_contracts['change_load'] == 1) & (filtered_contracts['restrictions'] == 0), 'new_contract'] = filtered_contracts['load_requested']\n",
    "# filtered_contracts.loc[(filtered_contracts['change_load'] == 1) & (filtered_contracts['restrictions'] == 0) & (filtered_contracts['load_requested'].isnull()), 'new_contract'] = np.minimum(filtered_contracts['contract'] * 2, 0.5)\n",
    "\n",
    "# Apply conditions for updating new_contract based on change_load and restrictions\n",
    "# filtered_contracts.loc[(filtered_contracts['change_load'] == 1) & (filtered_contracts['restrictions'] == 1), 'new_contract'] = filtered_contracts['contract']\n",
    "# filtered_contracts.loc[(filtered_contracts['change_load'] == 1) & (filtered_contracts['restrictions'] == 2), 'new_contract'] = np.maximum(filtered_contracts['contract'], 0.25)\n",
    "\n",
    "# Fill NaN values with the original contract value\n",
    "# ADDED! Caps \"CONTRACT\"\n",
    "filtered_contracts['new_contract'].fillna(filtered_contracts['CONTRACT'], inplace=True)\n",
    "\n",
    "# Create a new column \"new_contract\" in the original DataFrame with NaN values\n",
    "all_contracts['new_contract'] = np.nan\n",
    "\n",
    "# Update the \"new_contract\" column in the original DataFrame with the filtered values\n",
    "all_contracts.update(filtered_contracts[['new_contract']])\n",
    "# ADDED! Caps \"CONTRACT\"\n",
    "all_contracts['new_contract'].fillna(all_contracts['CONTRACT'], inplace=True)\n",
    "\n",
    "# Round the \"new_contract\" values to the closest contract level (0.125, 0.25, 0.375, 0.5)\n",
    "# all_contracts['new_contract'] = all_contracts['new_contract'].apply(round_to_closest)\n",
    "\n",
    "# Drop emails which currently do not have a contract (ex. pedro.brinca)\n",
    "# ADDED! Caps \"CONTRACT\"\n",
    "all_contracts = all_contracts[all_contracts.CONTRACT.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no TAs wihout current contract\n",
    "all_contracts[all_contracts.CONTRACT.isnull()].TA.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_contracts = all_contracts[[\"TA\", \"new_contract\", \"master_student\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Merge SUPPLY and DEMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_preferences = adapted_df.merge(all_contracts, how=\"left\", on=\"TA\", indicator=True)\n",
    "ta_preferences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for non-matching TAs\n",
    "non_matching_values = ta_preferences[ta_preferences['_merge'] != 'both']\n",
    "ta_preferences.drop(columns=[\"_merge\"], inplace=True)\n",
    "display(non_matching_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = ta_preferences.merge(course_demand, how=\"left\", on=\"course\", indicator=True)\n",
    "\n",
    "# market['number_classes'] = pd.to_numeric(market['number_classes'], errors='coerce').astype(pd.Int64Dtype())\n",
    "# market['number_students'] = pd.to_numeric(market['number_students'], errors='coerce').astype(pd.Int64Dtype())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_matching_values = market[market['_merge'] != 'both']\n",
    "market.drop(columns=[\"_merge\"], inplace=True)\n",
    "\n",
    "non_matching_courses = non_matching_values[[\"course\"]].drop_duplicates()\n",
    "non_matching_courses = non_matching_courses.copy()\n",
    "non_matching_courses[[\"course_code\", \"course_name\", \"period\", \"language\"]] = non_matching_courses[\"course\"].str.split(\" \\|\\| \", expand=True)\n",
    "\n",
    "course_demand_extended = course_demand.copy()\n",
    "course_demand_extended[[\"course_code\", \"course_name\", \"period\", \"language\"]] = course_demand[\"course\"].str.split(\" \\|\\| \", expand=True)\n",
    "course_demand_extended = course_demand_extended[[\"course\", \"course_code\", \"course_name\", \"period\", \"language\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the concatenated results\n",
    "concatenated_matches = pd.DataFrame()\n",
    "\n",
    "# Merge on 'course_code', 'period', and 'language'\n",
    "merged_courses = pd.merge(non_matching_courses, course_demand_extended, on=[\"course_code\", \"period\", \"language\"], how=\"left\", suffixes=(\"\", \"_new\"))\n",
    "still_unmatched = merged_courses[merged_courses[\"course_new\"].isna()][[\"course\", \"course_name\", \"course_code\", \"period\", \"language\"]]\n",
    "concatenated_matches = pd.concat([concatenated_matches, merged_courses[~merged_courses[\"course_new\"].isna()][[\"course\", \"course_new\"]]])\n",
    "\n",
    "# Merge on 'course_name', 'period', and 'language'\n",
    "merged_courses = pd.merge(still_unmatched, course_demand_extended, on=[\"course_name\", \"period\", \"language\"], how=\"left\", suffixes=(\"\", \"_new\"))\n",
    "still_unmatched = merged_courses[merged_courses[\"course_new\"].isna()][[\"course\", \"course_name\", \"course_code\", \"period\", \"language\"]]\n",
    "concatenated_matches = pd.concat([concatenated_matches, merged_courses[~merged_courses[\"course_new\"].isna()][[\"course\", \"course_new\"]]])\n",
    "\n",
    "# Merge on 'course_code' and 'period'\n",
    "merged_courses = pd.merge(still_unmatched, course_demand_extended, on=[\"course_code\", \"period\"], how=\"left\", suffixes=(\"\", \"_new\"))\n",
    "still_unmatched = merged_courses[merged_courses[\"course_new\"].isna()][[\"course\", \"course_name\", \"course_code\", \"period\", \"language\"]]\n",
    "concatenated_matches = pd.concat([concatenated_matches, merged_courses[~merged_courses[\"course_new\"].isna()][[\"course\", \"course_new\"]]])\n",
    "\n",
    "# # [DANGER! Might include courses from different semester] Merge on 'course_code' and 'language' \n",
    "# merged_courses = pd.merge(still_unmatched, course_demand_extended, on=[\"course_code\", \"language\"], how=\"left\", suffixes=(\"\", \"_new\"))\n",
    "# still_unmatched = merged_courses[merged_courses[\"course_new\"].isna()][[\"course\", \"course_name\", \"course_code\", \"period\", \"language\"]]\n",
    "# concatenated_matches = pd.concat([concatenated_matches, merged_courses[~merged_courses[\"course_new\"].isna()][[\"course\", \"course_new\"]]])\n",
    "\n",
    "# Merge concatenated_matches on the market DataFrame to add the \"course_new\" column\n",
    "market = pd.merge(market, concatenated_matches[[\"course\", \"course_new\"]], on=[\"course\"], how=\"left\")\n",
    "market[\"course_new\"].fillna(market[\"course\"], inplace=True)\n",
    "market.rename(columns={\"course\": \"course_old\"}, inplace=True)\n",
    "market.drop(columns=[\"course_old\"], inplace=True)\n",
    "market.rename(columns={\"course_new\": \"course\"}, inplace=True)\n",
    "\n",
    "# Merge market and course_demand on \"course\" column\n",
    "merged_market = pd.merge(market, course_demand[[\"course\", \"number_classes\", \"number_students\"]], on=\"course\", how=\"left\", suffixes=(\"\", \"_demand\"))\n",
    "\n",
    "# Fill NaN values in number_classes and number_students columns\n",
    "merged_market[\"number_classes\"].fillna(merged_market[\"number_classes_demand\"], inplace=True)\n",
    "merged_market[\"number_students\"].fillna(merged_market[\"number_students_demand\"], inplace=True)\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "merged_market.drop(columns=[\"number_classes_demand\", \"number_students_demand\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT #4\n",
    "# Display the updated merged_market DataFrame\n",
    "no_matches_final = merged_market[(merged_market.number_classes.isna()) | (merged_market.number_students.isna())][[\"course\"]]\n",
    "no_matches_final = no_matches_final.drop_duplicates()\n",
    "display(no_matches_final)\n",
    "\n",
    "# Drop these courses\n",
    "merged_market.dropna(subset=[\"number_classes\", \"number_students\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Compute capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the \"semester\" column based on the condition\n",
    "merged_market['semester'] = merged_market['course'].apply(lambda x: 1 if x.split(' || ')[2].startswith('S') else 0)\n",
    "# merged_market['ms_capacity'] = merged_market['new_contract'] * 36\n",
    "\n",
    "display(merged_market[(merged_market['semester'].isnull() | merged_market['masters_course'].isnull())])\n",
    "\n",
    "# Define a function to apply the conditions\n",
    "def calculate_weight(row):\n",
    "    if pd.isnull(row['semester']) or pd.isnull(row['masters_course']):\n",
    "        return np.nan\n",
    "    elif row['semester'] == 1 and row['masters_course'] == 1:\n",
    "        return ((row['number_students'] * 2.33) / 16) / 36\n",
    "    elif row['semester'] == 0 and row['masters_course'] == 1:\n",
    "        return ((row['number_students'] * 1.25) / 16) / 36\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the 'ms_weight' column\n",
    "merged_market['weight'] = merged_market.apply(calculate_weight, axis=1)\n",
    "\n",
    "# Set 'ms_capacity' to NaN when 'masters_course' is 0\n",
    "# merged_market.loc[merged_market['masters_course'] == 0, 'ms_capacity'] = np.nan\n",
    "# merged_market.loc[merged_market['masters_course'] == 0, 'ms_weight'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_market[merged_market.TA==\"bernardo.costa@novasbe.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_market.masters_course.value_counts(dropna=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file course list to manually input the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_demand_extended['masters_course'] = course_demand_extended['course'].apply(lambda x: 0 if x.split(' ')[0].startswith('1') else 1)\n",
    "course_demand_extended_bs = course_demand_extended[course_demand_extended.masters_course==0]\n",
    "course_demand_extended_bs = course_demand_extended_bs.drop(columns=[\"masters_course\"])\n",
    "course_demand_extended_bs[\"weight\"] = \"\"\n",
    "course_demand_extended_bs.to_excel(\"bs_courses_weights_EMPTY.xlsx\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the manually inputed weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_weights_df = pd.read_excel(bs_weights)[[\"course\", \"weight\"]]\n",
    "bs_weights_df[\"weight\"] = bs_weights_df[\"weight\"] * 0.125\n",
    "bs_weights_df.weight.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_market = pd.merge(merged_market, bs_weights_df, on=[\"course\"], how=\"left\", suffixes=(\"\", \"_bs\"), indicator=True)\n",
    "final_market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no BS courses without weight\n",
    "final_market[(final_market[\"_merge\"] != \"both\") & (final_market.masters_course==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_market.rename(columns={\"new_contract\": \"capacity\"}, inplace=True) # \"weight\": \"bs_weight\", \n",
    "final_market.drop(columns=\"_merge\", inplace=True)\n",
    "\n",
    "# ADDED! multiply by number of classes\n",
    "final_market[\"weight\"] = final_market[\"weight\"].fillna(final_market[\"weight_bs\"] * final_market[\"number_classes\"])\n",
    "final_market.drop(columns=[\"weight_bs\"], inplace=True)\n",
    "\n",
    "# final_market.loc[final_market['masters_course'] == 1, 'bs_capacity'] = np.nan\n",
    "# final_market.loc[final_market['masters_course'] == 1, 'bs_weight'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas = final_market.TA.unique()\n",
    "\n",
    "# Find elements missing in array1 compared to array2\n",
    "missing_elements = np.setdiff1d(completed_preferences, tas)\n",
    "\n",
    "# OUTPUT #N: TAs affected by unmatched courses\n",
    "print(missing_elements)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_market[final_market.TA==\"bernardo.costa@novasbe.pt\"].sort_values(by=['preference_type', 'preference'],ascending=[False,True])\n",
    "final_market[final_market.TA==\"fabian.wassmann@novasbe.pt\"].sort_values(by=['preference_type', 'preference'],ascending=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_market[final_market.course=='2866 || Work Project* || S1 || EN'].sort_values(by=['preference_type', 'preference'],ascending=[False,True]) # '1117 || Introdução à Microeconomia || S1 || EN'\n",
    "# final_market[final_market.course==\"2597 || Advanced Data Analysis || S1 || EN\"].sort_values(by=['preference_type', 'preference'],ascending=[False,True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_market[final_market.course=='1117 || Introdução à Microeconomia || S1 || EN'].sort_values(by=['preference', 'preference_type'],ascending=[True,True])\n",
    "# final_market[final_market.course=='1118 || Introdução à Macroeconomia || S1 || PT'].sort_values(by=['preference_type', 'preference'],ascending=[True,True])\n",
    "final_market[final_market.course== '1318 || Programação || S1 || EN'].sort_values(by=['preference_type', 'preference'],ascending=[True,True])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_dict = final_market[['TA','capacity']].drop_duplicates()\n",
    "ta_dict = dict(zip(ta_dict['TA'], ta_dict['capacity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED 'preference_type' == 2\n",
    "ms_courses = final_market[(final_market['masters_course'] == 1) & (final_market['master_student'] == 0) & ((final_market['preference_type'] == 2) | (final_market['preference_type'] == 1)) & (final_market['preference'] == 1)]\n",
    "\n",
    "ms_courses_dict = ms_courses[['course','weight']].drop_duplicates()\n",
    "ms_courses_dict = dict(zip(ms_courses_dict['course'], ms_courses_dict['weight']))\n",
    "\n",
    "# ADDED 'preference_type' == 2\n",
    "bs_courses = final_market[(final_market['masters_course'] == 0) & ((final_market['preference_type'] == 0) | (final_market['preference_type'] == 1)) & (final_market['preference'] == 1)]\n",
    "\n",
    "bs_courses_dict = bs_courses[['course','weight']].drop_duplicates()\n",
    "bs_courses_dict = dict(zip(bs_courses['course'], bs_courses['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_final_preferences = ms_courses[[\"TA\", \"preference_type\", \"preference\", \"course\", \"semester\"]]\n",
    "ms_final_preferences = ms_final_preferences.sort_values(by=[\"course\", \"preference_type\", \"preference\"], ascending=[True, False, True])\n",
    "\n",
    "bs_final_preferences = bs_courses[[\"TA\", \"preference_type\", \"preference\", \"course\", \"semester\"]]\n",
    "bs_final_preferences = bs_final_preferences.sort_values(by=[\"course\", \"preference_type\", \"preference\"], ascending=[True, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ms_final_preferences.course.unique()))\n",
    "print(len(bs_final_preferences.course.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the number of observations for each course and preference\n",
    "# course_preference_counts = ms_final_preferences.groupby(['course', 'preference']).size().reset_index(name='count')\n",
    "# # Filter out the courses with more than one observation for preference == 1\n",
    "# filtered_courses = course_preference_counts.loc[(course_preference_counts['preference'] == 1) & (course_preference_counts['count'] == 1), 'course']\n",
    "# # Filter the original DataFrame based on the filtered courses\n",
    "# ms_final_preferences_filtered = ms_final_preferences[ms_final_preferences['course'].isin(filtered_courses)]\n",
    "\n",
    "# # Print the filtered DataFrame\n",
    "# print(len(ms_final_preferences_filtered.course.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count the number of observations for each course and preference\n",
    "# course_preference_counts = bs_final_preferences.groupby(['course', 'preference']).size().reset_index(name='count')\n",
    "# # Filter out the courses with more than one observation for preference == 1\n",
    "# filtered_courses = course_preference_counts.loc[(course_preference_counts['preference'] == 1) & (course_preference_counts['count'] == 1), 'course']\n",
    "# # Filter the original DataFrame based on the filtered courses\n",
    "# bs_final_preferences_filtered = bs_final_preferences[bs_final_preferences['course'].isin(filtered_courses)]\n",
    "\n",
    "# # Print the filtered DataFrame\n",
    "# print(len(bs_final_preferences_filtered.course.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_allocations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in bs_final_preferences.iterrows():\n",
    "    ta = row['TA']\n",
    "    course = row['course']\n",
    "    ta_capacity = ta_dict[ta]\n",
    "    course_weight = bs_courses_dict[course]\n",
    "    # Check if course can be allocated\n",
    "    if course_weight > 0:\n",
    "        # Check if TA still has capacity\n",
    "        if  ta_capacity > 0:\n",
    "            allocated_weight = min(course_weight, ta_capacity)\n",
    "            # Allocate course to TA\n",
    "            ta_allocations.append((ta, course, allocated_weight))\n",
    "            ta_dict[ta] -= allocated_weight\n",
    "            bs_courses_dict[course] -= allocated_weight\n",
    "        else:\n",
    "            try:\n",
    "                bs_final_preferences = bs_final_preferences[bs_final_preferences['ta'] != ta]\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        bs_final_preferences = bs_final_preferences[bs_final_preferences['course'] != course]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in ms_final_preferences.iterrows():\n",
    "    ta = row['TA']\n",
    "    course = row['course']\n",
    "    ta_capacity = ta_dict[ta]\n",
    "    course_weight = ms_courses_dict[course]\n",
    "    # Check if course can be allocated\n",
    "    if course_weight > 0:\n",
    "        # Check if TA still has capacity\n",
    "        if  ta_capacity > 0:\n",
    "            allocated_weight = min(course_weight, ta_capacity)\n",
    "            # Allocate course to TA\n",
    "            ta_allocations.append((ta, course, allocated_weight))\n",
    "            ta_dict[ta] -= allocated_weight\n",
    "            ms_courses_dict[course] -= allocated_weight\n",
    "        else:\n",
    "            try:\n",
    "                ms_final_preferences = ms_final_preferences[ms_final_preferences['ta'] != ta]\n",
    "            except:\n",
    "                continue\n",
    "    else:\n",
    "        ms_final_preferences = ms_final_preferences[ms_final_preferences['course'] != course]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all courses and the respective capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_courses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_courses.CYCLE.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_courses[full_courses.course==\"127895 || Space for Business || T2 || EN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_weights_df[bs_weights_df.course==\"1114 || Economia Global II || S1 || EN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames\n",
    "full_course_weights = full_courses.merge(bs_weights_df, on=\"course\", how=\"left\")\n",
    "full_course_weights.rename(columns={\"course\": \"COURSE\"}, inplace=True)\n",
    "\n",
    "# Condition: If \"CYCLE\" == \"BSC\"\n",
    "mask_bs = full_course_weights[\"CYCLE\"] == \"BSC\"\n",
    "full_course_weights.loc[mask_bs, \"INITIAL NEEDS\"] = full_course_weights.loc[mask_bs, \"CLASS\"] * full_course_weights.loc[mask_bs, \"weight\"]\n",
    "\n",
    "# Condition: If \"CYCLE\" == \"MST\"\n",
    "mask_ms = full_course_weights[\"CYCLE\"] == \"MST\" \n",
    "def calculate_weight(row):\n",
    "    if pd.isnull(row['TERM']) or pd.isnull(row['CYCLE']):\n",
    "        return np.nan\n",
    "    elif row['TERM'].startswith('S') and row['CYCLE'] == 'MST':\n",
    "        return ((row['SLOTS'] * 2.33) / 16 ) / 36\n",
    "    elif row['TERM'].startswith('T') and row['CYCLE'] == 'MST':\n",
    "        return ((row['SLOTS'] * 1.25) / 16) / 36\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "full_course_weights.loc[mask_ms, \"INITIAL NEEDS\"] = full_course_weights.loc[mask_ms].apply(calculate_weight, axis=1)\n",
    "full_course_weights.drop(columns=\"weight\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ta_allocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_market[final_market.masters_course==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique courses from the final_market dataframe\n",
    "# all_courses = full_course_weights['COURSE'].unique()\n",
    "\n",
    "# # Create a dataframe for the courses and their needs\n",
    "# course_needs = pd.DataFrame({\n",
    "#     \"COURSE\": all_courses,\n",
    "#     \"INITIAL NEEDS\": [final_market[final_market['course'] == course]['weight'].values[0] for course in all_courses],\n",
    "#     \"NEEDS\": [ms_courses_dict.get(course, bs_courses_dict.get(course, final_market[final_market['course'] == course]['weight'].values[0])) for course in all_courses],\n",
    "#     \"CYCLE\": [\"MS\" if final_market[final_market['course'] == course]['masters_course'].values[0] == 1 else \"BS\" for course in all_courses]\n",
    "# })\n",
    "\n",
    "# # Multiply NEEDS and INITIAL NEEDS by 36 for CYCLE == MS\n",
    "# course_needs.loc[course_needs[\"CYCLE\"] == \"MS\", [\"NEEDS\", \"INITIAL NEEDS\"]] *= 36\n",
    "\n",
    "# # Add the MATCH column based on the conditionsa\n",
    "# course_needs.loc[course_needs[\"CYCLE\"] == \"ME\", \"MATCH\"] = \"NO\"\n",
    "# course_needs.loc[course_needs[\"INITIAL NEEDS\"] == course_needs[\"NEEDS\"], \"MATCH\"] = \"NO\"\n",
    "# course_needs.loc[(course_needs[\"INITIAL NEEDS\"] != course_needs[\"NEEDS\"]) & (course_needs[\"NEEDS\"] > 0), \"MATCH\"] = \"PARTIAL\"\n",
    "# course_needs.loc[(course_needs[\"INITIAL NEEDS\"] != course_needs[\"NEEDS\"]) & (course_needs[\"NEEDS\"] == 0), \"MATCH\"] = \"MATCHED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique courses from the full_course_weights dataframe\n",
    "all_courses = full_course_weights['COURSE'].unique()\n",
    "\n",
    "# Create a dataframe for the courses and their needs\n",
    "course_needs = pd.DataFrame({\n",
    "    \"CYCLE\": full_course_weights.loc[full_course_weights['COURSE'].isin(all_courses), 'CYCLE'],\n",
    "    \"COURSE\": all_courses,\n",
    "    \"TERM\": [full_course_weights[full_course_weights['COURSE'] == course]['TERM'].values[0] for course in all_courses],\n",
    "    \"CLASSES\": [full_course_weights[full_course_weights['COURSE'] == course]['CLASS'].values[0] for course in all_courses],\n",
    "    \"SLOTS\": [full_course_weights[full_course_weights['COURSE'] == course]['SLOTS'].values[0] for course in all_courses],\n",
    "    \"INITIAL NEEDS\": [full_course_weights[full_course_weights['COURSE'] == course]['INITIAL NEEDS'].values[0] for course in all_courses],\n",
    "    \"NEEDS\": [ms_courses_dict.get(course, bs_courses_dict.get(course, full_course_weights[full_course_weights['COURSE'] == course]['INITIAL NEEDS'].values[0])) for course in all_courses]\n",
    "    \n",
    "})\n",
    "\n",
    "# Multiply NEEDS and INITIAL NEEDS by 36 for CYCLE == MS\n",
    "course_needs.loc[course_needs[\"CYCLE\"] == \"MST\", [\"NEEDS\", \"INITIAL NEEDS\"]] *= 36\n",
    "\n",
    "# Add the MATCH column based on the conditionsa\n",
    "course_needs.loc[course_needs[\"CYCLE\"] == \"ME\", \"MATCH\"] = \"NO\"\n",
    "course_needs.loc[course_needs[\"INITIAL NEEDS\"] == course_needs[\"NEEDS\"], \"MATCH\"] = \"NO\"\n",
    "course_needs.loc[(course_needs[\"INITIAL NEEDS\"] != course_needs[\"NEEDS\"]) & (course_needs[\"NEEDS\"] > 0), \"MATCH\"] = \"PARTIAL\"\n",
    "course_needs.loc[(course_needs[\"INITIAL NEEDS\"] != course_needs[\"NEEDS\"]) & (course_needs[\"NEEDS\"] == 0), \"MATCH\"] = \"MATCHED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_course_weights.shape)\n",
    "full_course_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(course_needs.shape)\n",
    "display(course_needs.head())\n",
    "course_needs.to_excel(\"course_needs.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_needs.CYCLE.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for the TA allocations\n",
    "ta_allocations_df = pd.DataFrame(ta_allocations, columns=[\"TA\", \"COURSE\", \"LOAD\"])\n",
    "ta_allocations_df[\"CYCLE\"] = ta_allocations_df[\"COURSE\"].apply(lambda x: \"MST\" if x in ms_courses_dict else \"BSC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ta_allocations_df.shape)\n",
    "new_order = ['CYCLE', 'COURSE', 'TA', 'LOAD']\n",
    "ta_allocations_df = ta_allocations_df[new_order]\n",
    "display(ta_allocations_df.head())\n",
    "ta_allocations_df.to_excel(\"ta_allocations_auto.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms_courses_dict_filtered = {k: v for k, v in ms_courses_dict.items() if v == 0}\n",
    "# len(ms_courses_dict_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ms_courses_dict_filtered = {k: v for k, v in ms_ta_dict.items() if v < 5}\n",
    "# len(ms_courses_dict_filtered)\n",
    "# ms_courses_dict_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses_dict = final_market[['course','weight']].drop_duplicates()\n",
    "# courses_dict = dict(zip(courses_dict['course'], courses_dict['weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# course_preference_counts = final_preferences.groupby(['course', 'preference']).size().reset_index(name='count')\n",
    "\n",
    "# # Filter out the courses with more than one observation for preference == 1\n",
    "# filtered_courses = course_preference_counts.loc[(course_preference_counts['preference'] == 1) & (course_preference_counts['count'] == 1), 'course']\n",
    "# final_preferences_filtered = final_preferences[final_preferences['course'].isin(filtered_courses)]\n",
    "\n",
    "# # Print the filtered DataFrame\n",
    "# print(len(final_preferences_filtered.course.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_preferences = final_market[[\"TA\", \"preference_type\", \"preference\", \"course\", \"semester\", \"master_student\", \"masters_course\"]]\n",
    "# final_preferences = final_preferences.sort_values(by=[\"course\", \"preference_type\", \"preference\"], ascending=[True, False, True])\n",
    "# final_preferences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(final_preferences.course.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta_allocations = []\n",
    "\n",
    "# for _, row in final_preferences_filtered.iterrows():\n",
    "#     ta = row['TA']\n",
    "#     pref_type = row['preference_type']\n",
    "#     course = row['course']\n",
    "#     student = row['master_student']\n",
    "#     ms_course = row['masters_course']\n",
    "\n",
    "#     ta_capacity = ta_dict[ta]\n",
    "#     course_weight = courses_dict[course]\n",
    "\n",
    "#     # MS courses\n",
    "#     if ms_course == 1 and student == 0:\n",
    "#         # Give priority to TAs who want MS courses\n",
    "#         if pref_type == 1 or pref_type == 2:\n",
    "#             # Check if course can be allocated\n",
    "#             if course_weight > 0:\n",
    "#                 # Check if TA still has capacity\n",
    "#                 if  ta_capacity > 0:\n",
    "#                     allocated_weight = min(course_weight, ta_capacity)\n",
    "#                     # Allocate course to TA\n",
    "#                     ta_allocations.append((ta, course, allocated_weight))\n",
    "#                     ta_dict[ta] -= allocated_weight\n",
    "#                     courses_dict[course] -= allocated_weight\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['ta'] != ta]\n",
    "#                     except:\n",
    "#                         continue\n",
    "#             else:\n",
    "#                 final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['course'] != course]\n",
    "#         else:\n",
    "#             continue\n",
    "    \n",
    "#     elif ms_course == 0:\n",
    "#         # Give priority to TAs who want BS courses\n",
    "#         if pref_type == 0:\n",
    "#             # Check if course can be allocated\n",
    "#             if course_weight > 0:\n",
    "#                 # Check if TA still has capacity\n",
    "#                 if  ta_capacity > 0:\n",
    "#                     allocated_weight = min(course_weight, ta_capacity)\n",
    "#                     # Allocate course to TA\n",
    "#                     ta_allocations.append((ta, course, allocated_weight))\n",
    "#                     ta_dict[ta] -= allocated_weight\n",
    "#                     courses_dict[course] -= allocated_weight\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['ta'] != ta]\n",
    "#                     except:\n",
    "#                         continue\n",
    "#             else:\n",
    "#                 final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['course'] != course]\n",
    "#         else:\n",
    "#             continue\n",
    "#     else:\n",
    "#         if course_weight > 0:\n",
    "#             # Check if TA still has capacity\n",
    "#             if  ta_capacity > 0:\n",
    "#                 allocated_weight = min(course_weight, ta_capacity)\n",
    "#                 # Allocate course to TA\n",
    "#                 ta_allocations.append((ta, course, allocated_weight))\n",
    "#                 ta_dict[ta] -= allocated_weight\n",
    "#                 courses_dict[course] -= allocated_weight\n",
    "#             else:\n",
    "#                 try:\n",
    "#                     final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['ta'] != ta]\n",
    "#                 except:\n",
    "#                     continue\n",
    "#         else:\n",
    "#             final_preferences_filtered = final_preferences_filtered[final_preferences_filtered['course'] != course]            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adpro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "741b156619ec336ecb48b7fb7dbd765270d1cf601d0723149adda69f4dd9d34a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
